{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DatathonTips.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaoimheCarbery/AI-NI-Datathon/blob/master/Python_Datathon_Tips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvPAzSCLkeTG",
        "colab_type": "text"
      },
      "source": [
        "#Datathon Tips\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsygDHASvJrO",
        "colab_type": "text"
      },
      "source": [
        "The code snippits will help give you an idea of getting started in Python for data cleaning and quality checking! The code snippit below is an example of how to install a package in python and to load it in the console. \n",
        "\n",
        "You can use Jupyter online, Anaconda, R, R Studio! whatever you what, this is some examples for Python! \n",
        "\n",
        "##Install package\n",
        "\n",
        "In your command line (type _cmd_ in the search bar on your machine) type in the following to install a package in python.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWpuT7deklW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install scikit-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p03mvWC5myDn",
        "colab_type": "text"
      },
      "source": [
        "Once a package is installed you can then import the library using the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHa9Ze6Jm7fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Pandas library as pd\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5hivz35qBpV",
        "colab_type": "text"
      },
      "source": [
        "Below are some useful libraries in Python that can help with data exploration, visualisation and data cleaning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lczQsSq4qZiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd  #for data manipulation and analysis\n",
        "import numpy as np   #useful for data manipultion and working with different formats of data\n",
        "import seaborn as sns #Statitical data visualisation\n",
        "import scikit-learn as sklearn #Machine learning library with different algorithms for building models\n",
        "from matplotlib.pyplot import pyplot as plt #plotting library and uses numpy!\n",
        "import Dora #Exploratory Data Analysis\n",
        "import tensorflow as tf #Useful ML library\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxJkbGSJsPQ3",
        "colab_type": "text"
      },
      "source": [
        "###Importing specific classes from libraries examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1rbY4VZsUNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from datacleaner import autoclean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgBHKxivtrph",
        "colab_type": "text"
      },
      "source": [
        "###Creating training and testing split. (Look at other methods for splitting data too)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2uCH3XStzf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "#Load dataset and turn into pandas dataframe\n",
        "\n",
        "Smashfly = pd.read_csv(\"SF_Datathon_Data.csv\") \n",
        "sf_df= pd.DataFrame(Smashfly)\n",
        "\n",
        "#define target variable\n",
        "y = Smashfly.Interview\n",
        "\n",
        "#Create training and testing split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sf_df,y,test_size=0.3, random_state=123) #This creates a split of 70% training and 30% testing. Can do other splits and other ways. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGzng4u6NbY_",
        "colab_type": "text"
      },
      "source": [
        "[Splitting dataset using scikit-learn](https://medium.com/@contactsunny/how-to-split-your-dataset-to-train-and-test-datasets-using-scikit-learn-e7cf6eb5e0d)\n",
        "\n",
        "[Cross-validation in Scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHLT3-EDCxsV",
        "colab_type": "text"
      },
      "source": [
        "##One-hot encoding\n",
        "Have a look at one-hot encoding if needed. Check out your data, the format etc. What type of algorithms do you want to try?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eux_mgD9C7Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify categorical columns\n",
        "\n",
        "cat_columns = [\"var1\",\"var2\",...]\n",
        "\n",
        "df_processed = pd.get_dummies(df, prefix_sep=\"_\", columns=cat_columns)\n",
        "\n",
        "#Or as an alternative there are functionalities within scikit-learn for one-hot encoding\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7vzN9PtNs64",
        "colab_type": "text"
      },
      "source": [
        "[One-hot encoding in Python](https://blog.cambridgespark.com/robust-one-hot-encoding-in-python-3e29bfcec77e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeaddwARH18W",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "It's important to perform exploratory data analysis and clean up your data. This is usually a cycle and you need to understand what needs cleaned.\n",
        " \n",
        "I've added in some pieces of code that might be useful!\n",
        "\n",
        "###Visualising your dataset\n",
        "\n",
        "Try out the seaborn library. Seaborn works best with Pandas DataFrames.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7MPI59VJ7Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure the necessary libraries are imported\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set()\n",
        "\n",
        "# Make sure data is loaded\n",
        "\n",
        "#Construct plot\n",
        "\n",
        "sns.swarmplot(x=\"var1\", y=\"var2\", data=df) #specify the x and y axis you are looking to explore/compare. Numeric features.\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Distribution plot\n",
        "\n",
        "sns.distplot(df['var1'])\n",
        "sns.distplot(df['var2']); #Overlay the distribution of two features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EH-9dcLNH8I",
        "colab_type": "text"
      },
      "source": [
        "[Seaborn Python Tutorial](https://www.datacamp.com/community/tutorials/seaborn-python-tutorial)\n",
        "\n",
        "[Seaborn visualisations with categorical data](https://seaborn.pydata.org/tutorial/categorical.html)\n",
        "\n",
        "[Seaborn Visualisations](https://jakevdp.github.io/PythonDataScienceHandbook/04.14-visualization-with-seaborn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaygHgeWLWsh",
        "colab_type": "text"
      },
      "source": [
        "### Generating summary statistics\n",
        "\n",
        "Useful to get a high level overview of the dataset by performing summary statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBFJ0bZVL3TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import trim_mean, kurtotis\n",
        "from scipy.stats.mstats import mode, gmean, hmean\n",
        "\n",
        "\n",
        "df.describe()\n",
        "\n",
        "data_by_group= df.groupby(['var1','var2'])\n",
        "data_by_group['var3'].describe().unstack()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ05CXe2MRzI",
        "colab_type": "text"
      },
      "source": [
        "### Other things to check\n",
        "\n",
        "There are a few other things you can check - such as missing data. Try and explore the best way to address this. What other features could you create?\n",
        "\n",
        "- What other data steps are needed before you can implement into an AI algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB_CIslUMtmy",
        "colab_type": "text"
      },
      "source": [
        "## Feature Importance\n",
        "\n",
        "Feature importance and significance can be used in ML models to detect any bias in the model. \n",
        "\n",
        "[Feature Section in scikit-learn](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "\n",
        "\n",
        "[Feature Selection with sklearn and Pandas](https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhqg8xHDOUkR",
        "colab_type": "text"
      },
      "source": [
        "### Identifying Missing Values\n",
        "Important to do a quick check for missing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2KviwGeO-UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Any missing values?\n",
        "print df.isnull().values.any()\n",
        "\n",
        "# Total number of missing values\n",
        "print df.isnull().sum().sum()\n",
        "\n",
        "# Total missing values for each feature\n",
        "print df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD52uleeQPpw",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning libraries\n",
        "\n",
        "There are a few libraries in Python that can allow you to explore and implement ML algorithms\n",
        "\n",
        "- scikit-learn\n",
        "- tensorflow\n",
        "- keras"
      ]
    }
  ]
}